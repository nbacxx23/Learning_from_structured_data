{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import operator\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = treebank.tagged_sents()\n",
    "new_sentences=[]\n",
    "for s in sentences:\n",
    "    sen=[]\n",
    "    for w in s:\n",
    "        if w[1] != '-NONE-':\n",
    "            sen.append(w)\n",
    "    new_sentences.append(sen)\n",
    "max_length = 271\n",
    "max_tag = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(new_sentences, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for s in train_data:\n",
    "    for pair in s:\n",
    "        pairs.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_index(s):\n",
    "    dict_s = dict.fromkeys(s)\n",
    "    k = 0\n",
    "    for i in dict_s:\n",
    "        dict_s[i] = k\n",
    "        k +=1\n",
    "    return dict_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_inf(data):\n",
    "    word = set()\n",
    "    pos = set()\n",
    "    pairs = set()\n",
    "    for pair in data:\n",
    "        word.add(pair[0].lower())\n",
    "        pos.add(pair[1])\n",
    "        pairs.add(pair)\n",
    "    word = make_index(word)\n",
    "    pos = make_index(pos)\n",
    "    pairs = make_index(pairs)\n",
    "    return word,pos,pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_index,pos_index,pairs_index = data_inf(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def presentation_word(word, word_index):\n",
    "    l = len(word_index)+1\n",
    "    word_feat = np.zeros(l)\n",
    "    if word in word_index:\n",
    "        index = word_index[word]\n",
    "        word_feat[index] = 1\n",
    "        word_feat[-1]=1\n",
    "    else:\n",
    "        word_feat[-1] = 0\n",
    "    return word_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def presentation_pos(pos, pos_index):\n",
    "    l = len(pos_index)\n",
    "    index = pos_index[pos]\n",
    "    pos_feat = np.zeros(l)\n",
    "    pos_feat[index] = 1\n",
    "    return pos_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def presentation_pair(pair, pairs_index):\n",
    "    l = len(pairs_index)\n",
    "    index = pairs_index[pair]\n",
    "    pair_feat = np.zeros(l)\n",
    "    pair_feat[index] = 1\n",
    "    return pair_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def position_feature(position):\n",
    "    position_feat = np.zeros(max_length)\n",
    "    position_feat[position] = 1\n",
    "    return position_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def neighbors_word(position,sentence,word_index):\n",
    "    l = len(word_index)+1\n",
    "    length_sentence = len(sentence)\n",
    "    if position==0:\n",
    "        last_word_feat = np.zeros(l)\n",
    "        last_two_word_feat = np.zeros(l)\n",
    "    elif position ==1 :\n",
    "        last_word_feat = presentation_word(word=sentence[position-1],word_index=word_index)\n",
    "        last_two_word_feat = np.zeros(l)\n",
    "    else:\n",
    "        last_word_feat = presentation_word(word=sentence[position-1],word_index=word_index)\n",
    "        last_two_word_feat = presentation_word(word=sentence[position-2],word_index=word_index)\n",
    "    if length_sentence-position==1:\n",
    "        next_word_feat = np.zeros(l)\n",
    "        next_two_word_feat = np.zeros(l)\n",
    "    elif length_sentence-position == 2:\n",
    "        next_word_feat = presentation_word(word=sentence[position+1],word_index=word_index)\n",
    "        next_two_word_feat = np.zeros(l)\n",
    "    else:\n",
    "        next_word_feat = presentation_word(word=sentence[position+1],word_index=word_index)\n",
    "        next_two_word_feat = presentation_word(word=sentence[position+2],word_index=word_index)\n",
    "    return last_word_feat,last_two_word_feat,next_word_feat,next_two_word_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def neighbors_pos(position, sentence_pos):\n",
    "    last_pos_feat = np.zeros(max_tag+1)\n",
    "    last_two_pos_feat = np.zeros(max_tag+1)\n",
    "    next_pos_feat = np.zeros(max_tag+1)\n",
    "    next_two_pos_feat = np.zeros(max_tag+1)\n",
    "    #length of the sentence\n",
    "    max_length_sentence = len(sentence_pos)\n",
    "    #pos for neighbors\n",
    "    if position==0:\n",
    "        last_pos_feat[-1] = 1\n",
    "        last_two_pos_feat[-1] = 1\n",
    "        if max_length_sentence==1:\n",
    "            \n",
    "            next_pos_feat[-1]=1\n",
    "            next_two_pos_feat[-1]=1\n",
    "        elif max_length_sentence == 2:\n",
    "            next_pos_feat[sentence_pos[1]] = 1\n",
    "            next_two_pos_feat[-1] = 1\n",
    "        else:\n",
    "            next_pos_feat[sentence_pos[1]]=1\n",
    "            next_two_pos_feat[sentence_pos[2]] =1\n",
    "    elif position == 1:\n",
    "        last_pos_feat[sentence_pos[0]]=1\n",
    "        last_two_pos_feat[-1]=1\n",
    "        if max_length_sentence==2:\n",
    "            next_pos_feat[-1]=1\n",
    "            next_two_pos_feat[-1]=1\n",
    "        elif max_length==3:\n",
    "            next_pos_feat[sentence_pos[2]]=1\n",
    "            next_two_pos_feat[-1]=1\n",
    "        else:\n",
    "            next_pos_feat[sentence_pos[position+1]]=1\n",
    "            next_two_pos_feat[sentence_pos[position+2]]=1\n",
    "    else:\n",
    "        if position + 1 == max_length_sentence:\n",
    "            next_pos_feat[-1]=1\n",
    "            next_two_pos_feat[-1]=1\n",
    "            last_pos_feat[sentence_pos[position-1]]=1\n",
    "            last_two_pos_feat[sentence_pos[position-2]]=1\n",
    "        elif position + 2 == max_length_sentence:\n",
    "            next_pos_feat[sentence_pos[position+1]]=1\n",
    "            next_two_pos_feat[-1]=1\n",
    "            last_pos_feat[sentence_pos[position-1]]=1\n",
    "            last_two_pos_feat[sentence_pos[position-2]]=1\n",
    "        else:\n",
    "            next_pos_feat[sentence_pos[position+1]]=1\n",
    "            next_two_pos_feat[sentence_pos[position+2]]=1\n",
    "            last_pos_feat[sentence_pos[position-1]]=1\n",
    "            last_two_pos_feat[sentence_pos[position-2]]=1\n",
    "    return next_pos_feat,next_two_pos_feat,last_pos_feat,last_two_pos_feat\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w=[]\n",
    "t=[]\n",
    "t_index=[]\n",
    "pair = []\n",
    "for i in new_sentences[0]:\n",
    "    w.append(i[0])\n",
    "    t_index.append(pos_index[i[1]])\n",
    "    t.append(i[1])\n",
    "    pair.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_feat = presentation_word(w[0],word_index=word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_feat = presentation_pos(t[0], pos_index=pos_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_feat = presentation_pair(pair[0],pairs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighbors_pos_feat = neighbors_pos(position=0, sentence_pos=t_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = [i[0] for i in pairs]\n",
    "dict_words = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = sorted(dict_words.items(), key=operator.itemgetter(1))\n",
    "rare_words = []\n",
    "not_rare_words = []\n",
    "for i in s:\n",
    "    if i[1]<2:\n",
    "        rare_words.append(i[0])\n",
    "    else:\n",
    "        not_rare_words.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 0\n",
    "dict_alphabet=dict()\n",
    "for i in string.ascii_lowercase:\n",
    "    dict_alphabet[i]=k\n",
    "    k += 1\n",
    "dict_alphabet['symbol'] = 26\n",
    "k = 27\n",
    "for i in range(10):\n",
    "    dict_alphabet[str(i)] = k\n",
    "    k +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prefix_suffix_one(word):\n",
    "    l = 26+10+1+1\n",
    "    prefix_one_feat = np.zeros(l)\n",
    "    suffix_one_feat = np.zeros(l)\n",
    "    if word[0] not in string.ascii_lowercase and word not in string.digits:\n",
    "        prefix_one_feat[dict_alphabet['symbol']] = 1 \n",
    "    else:\n",
    "        prefix_one_feat[dict_alphabet[word[0]]] = 1\n",
    "    if word[-1]not in string.ascii_lowercase and word not in string.digits:\n",
    "        suffix_one_feat[dict_alphabet['symbol']] = 1\n",
    "    else:\n",
    "        suffix_one_feat[dict_alphabet[word[-1]]] = 1\n",
    "    return prefix_one_feat,suffix_one_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prefix_suffix_two(word):\n",
    "    l = 37 * 2\n",
    "    prefix_two_feat = np.zeros(l)\n",
    "    suffix_two_feat = np.zeros(l)\n",
    "    if len(word)==1:\n",
    "        if word[0] not in string.ascii_lowercase and word not in string.digits:\n",
    "            prefix_two_feat[dict_alphabet['symbol']]=1\n",
    "            suffix_two_feat[dict_alphabet['symbol']]=1\n",
    "        else:\n",
    "            prefix_two_feat[dict_alphabet[word[0]]]=1\n",
    "            suffix_two_feat[dict_alphabet[word[0]]]=1\n",
    "    else:\n",
    "        if word[0] not in string.ascii_lowercase and word not in string.digits:\n",
    "            prefix_two_feat[dict_alphabet['symbol']]=1\n",
    "        else:\n",
    "            prefix_two_feat[dict_alphabet[word[0]]] = 1\n",
    "        if word[1] not in string.ascii_lowercase and word not in string.digits:\n",
    "            prefix_two_feat[dict_alphabet['symbol'] + 37] =1\n",
    "        else:\n",
    "            prefix_two_feat[dict_alphabet[word[1]]+37] = 1\n",
    "        if word[-1] not in string.ascii_lowercase and word not in string.digits:\n",
    "            suffix_two_feat[dict_alphabet['symbol']]=1\n",
    "        else:\n",
    "            suffix_two_feat[dict_alphabet[word[-1]]]=1\n",
    "        if word[-2] not in string.ascii_lowercase and word not in string.digits:\n",
    "            suffix_two_feat[dict_alphabet['symbol']+37]=1\n",
    "        else:\n",
    "            suffix_two_feat[dict_alphabet[word[-2]]+37]=1\n",
    "    return prefix_two_feat,suffix_two_feat\n",
    "        \n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prefix_suffix_three(word):\n",
    "    l = 37 * 3\n",
    "    prefix_three_feat = np.zeros(l)\n",
    "    suffix_three_feat = np.zeros(l)\n",
    "    if len(word) == 1:\n",
    "        if word[0] not in string.ascii_lowercase and word not in string.digits:\n",
    "            prefix_three_feat[dict_alphabet['symbol']]=1\n",
    "            suffix_three_feat[dict_alphabet['symbol']]=1\n",
    "        else:\n",
    "            prefix_three_feat[dict_alphabet[word[0]]]=1\n",
    "            suffix_three_feat[dict_alphabet[word[0]]]=1\n",
    "    elif len(word) == 2 : \n",
    "        if word[0] not in string.ascii_lowercase and word not in string.digits:\n",
    "            prefix_three_feat[dict_alphabet['symbol']]=1\n",
    "        else:\n",
    "            prefix_three_feat[dict_alphabet[word[0]]] = 1\n",
    "        if word[1] not in string.ascii_lowercase and word not in string.digits:\n",
    "            prefix_three_feat[dict_alphabet['symbol'] + 37] =1\n",
    "        else:\n",
    "            prefix_three_feat[dict_alphabet[word[1]]+37] = 1\n",
    "        if word[-1] not in string.ascii_lowercase and word not in string.digits:\n",
    "            suffix_three_feat[dict_alphabet['symbol']]=1\n",
    "        else:\n",
    "            suffix_three_feat[dict_alphabet[word[-1]]]=1\n",
    "        if word[-2] not in string.ascii_lowercase and word not in string.digits:\n",
    "            suffix_three_feat[dict_alphabet['symbol']+37]=1\n",
    "        else:\n",
    "            suffix_three_feat[dict_alphabet[word[-2]]+37]=1\n",
    "    else:\n",
    "        if word[0] not in string.ascii_lowercase and word not in string.digits:\n",
    "            prefix_three_feat[dict_alphabet['symbol']]=1\n",
    "        else:\n",
    "            prefix_three_feat[dict_alphabet[word[0]]] = 1\n",
    "            \n",
    "            \n",
    "        if word[1] not in string.ascii_lowercase and word not in string.digits:\n",
    "            prefix_three_feat[dict_alphabet['symbol'] + 37] =1\n",
    "        else:\n",
    "            prefix_three_feat[dict_alphabet[word[1]]+37] = 1\n",
    "            \n",
    "            \n",
    "        if word[2] not in string.ascii_lowercase and word not in string.digits:\n",
    "            prefix_three_feat[dict_alphabet['symbol'] + 37+37] =1\n",
    "        else:\n",
    "            prefix_three_feat[dict_alphabet[word[2]]+37+37] = 1\n",
    "            \n",
    "            \n",
    "        if word[-1] not in string.ascii_lowercase and word not in string.digits:\n",
    "            suffix_three_feat[dict_alphabet['symbol']]=1\n",
    "        else:\n",
    "            suffix_three_feat[dict_alphabet[word[-1]]]=1\n",
    "        if word[-2] not in string.ascii_lowercase and word not in string.digits:\n",
    "            suffix_three_feat[dict_alphabet['symbol']+37]=1\n",
    "        else:\n",
    "            suffix_three_feat[dict_alphabet[word[-2]]+37]=1\n",
    "        if word[-3] not in string.ascii_lowercase and word not in string.digits:\n",
    "            suffix_three_feat[dict_alphabet['symbol']+37+37]=1\n",
    "        else:\n",
    "            suffix_three_feat[dict_alphabet[word[-3]]+37+37]=1\n",
    "    return prefix_three_feat,suffix_three_feat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contain_number(word):\n",
    "    contain_number_feat = np.zeros(1)\n",
    "    for i in word:\n",
    "        if i in string.digits:\n",
    "            contain_number_feat[0]=1\n",
    "    return contain_number_feat\n",
    "def contain_uppercase(word):\n",
    "    contain_uppercase_feat = np.zeros(1)\n",
    "    for i in word:\n",
    "        if i in string.uppercase:\n",
    "            contain_uppercase_feat[0]=1\n",
    "    return contain_uppercase_feat\n",
    "\n",
    "def contain_hyphen(word):\n",
    "    contain_hyphen_feat = np.zeros(1)\n",
    "    for i in word:\n",
    "        if i not in string.digits and i not in string.ascii_lowercase:\n",
    "            contain_hyphen_feat[0]=1\n",
    "    return contain_hyphen_feat\n",
    "\n",
    "def rare_word(word,rare_words,not_rare_words):\n",
    "    rare_word_feat = np.zeros(3)\n",
    "    if word in rare_words:\n",
    "        rare_word_feat[0]=1\n",
    "    elif word in not_rare_words:\n",
    "        rare_word_feat[1]=1\n",
    "    else: \n",
    "        rare_word_feat[2] = 1\n",
    "    return rare_word_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_word = words[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_suffix_three(test_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_feat = presentation_word(word=test_word,word_index=word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combination(position,sentence):\n",
    "    sentence_word = [i[0] for i in sentence]\n",
    "    sentence_tag = [i[1] for i in sentence]\n",
    "    \n",
    "    word = sentence[position][0]\n",
    "    tag = sentence[position][1]\n",
    "    pair = sentence[position]\n",
    "    \n",
    "    \n",
    "    word_feat = presentation_word(word=word.lower(),word_index=word_index)\n",
    "\n",
    "    \n",
    "    position_feat = position_feature(position)\n",
    "\n",
    "    \n",
    "    rare_word_feat = rare_word(word=word, rare_words=rare_words,not_rare_words=not_rare_words)\n",
    "\n",
    "    contain_number_feat = contain_number(word=word)\n",
    "    contain_uppercase_feat = contain_uppercase(word=word)\n",
    "    contain_hyphen_feat = contain_hyphen(word=word)\n",
    "    prefix_feat,suffix_feat = prefix_suffix_three(word=word.lower())\n",
    "    pair_feat = presentation_pair(pair=pair,pairs_index=pairs_index)\n",
    "    tag_feat = presentation_pos(pos=tag,pos_index=pos_index)\n",
    "    if position==0:\n",
    "        last_tag = np.zeros(max_tag)\n",
    "        last_two_tag = np.zeros(max_tag)\n",
    "    elif position ==1:\n",
    "        last_tag = presentation_pos(pos=sentence_tag[position-1],pos_index=pos_index)\n",
    "        last_two_tag = np.zeros(max_tag)\n",
    "    else:\n",
    "        last_tag = presentation_pos(pos=sentence_tag[position-1],pos_index=pos_index)\n",
    "        last_two_tag = presentation_pos(pos=sentence_tag[position-2],pos_index=pos_index)\n",
    "    last_word_feat,last_two_word_feat,next_word_feat,next_two_word_feat = neighbors_word(position=position,sentence=sentence_word,word_index=word_index)\n",
    "    feature_vector=np.concatenate((word_feat,position_feat,rare_word_feat,contain_number_feat,contain_hyphen_feat,contain_uppercase_feat,\n",
    "                                  prefix_feat,suffix_feat,pair_feat,tag_feat,last_tag,last_two_tag,last_word_feat,last_two_word_feat,next_word_feat,next_two_word_feat),axis=0)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_vector(position,sentence,tag,tag_1,tag_2):\n",
    "    #word-level features\n",
    "    word = sentence[position]\n",
    "    word_feat = presentation_word(word = word, word_index=word_index)\n",
    "    contain_number_feat = contain_number(word=word)\n",
    "    contain_uppercase_feat = contain_uppercase(word=word)\n",
    "    contain_hyphen_feat = contain_hyphen(word=word)\n",
    "    prefix_feat,suffix_feat = prefix_suffix_three(word=word.lower())\n",
    "    pair_feat = presentation_pair(pair=(word,tag),pairs_index=pairs_index)\n",
    "    \n",
    "    #tag-level features\n",
    "    tag_feat = presentation_pos(pos=tag, pos_index=pos_index)\n",
    "    tag_1_feat = presentation_pos(pos=tag_1,pos_index=pos_index)\n",
    "    tag_2_feat = presentation_pos(pos=tag_2,pos_index=pos_index)\n",
    "    #position feature\n",
    "    position_feat = position_feature(position=position)\n",
    "    last_word_feat,last_two_word_feat,next_word_feat,next_two_word_feat = neighbors_word(position=position,sentence=sentence,word_index=word_index)\n",
    "    feature_vector = np.concatenate((word_feat,contain_number_feat,contain_uppercase_feat,contain_hyphen_feat,\n",
    "        prefix_feat,suffix_feat,pair_feat,\n",
    "        tag_2_feat,tag_1_feat,tag_feat,\n",
    "        position_feat,last_word_feat,last_two_word_feat,next_word_feat,next_two_word_feat\n",
    "        ),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_sentences[0]\n",
    "sentence = [i[0] for i in new_sentences[0]]\n",
    "tag = [i[1] for i in new_sentences[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'Pierre',\n",
       "  u'Vinken',\n",
       "  u',',\n",
       "  u'61',\n",
       "  u'years',\n",
       "  u'old',\n",
       "  u',',\n",
       "  u'will',\n",
       "  u'join',\n",
       "  u'the',\n",
       "  u'board',\n",
       "  u'as',\n",
       "  u'a',\n",
       "  u'nonexecutive',\n",
       "  u'director',\n",
       "  u'Nov.',\n",
       "  u'29',\n",
       "  u'.'],\n",
       " [u'NNP',\n",
       "  u'NNP',\n",
       "  u',',\n",
       "  u'CD',\n",
       "  u'NNS',\n",
       "  u'JJ',\n",
       "  u',',\n",
       "  u'MD',\n",
       "  u'VB',\n",
       "  u'DT',\n",
       "  u'NN',\n",
       "  u'IN',\n",
       "  u'DT',\n",
       "  u'JJ',\n",
       "  u'NN',\n",
       "  u'NNP',\n",
       "  u'CD',\n",
       "  u'.'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence,tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_vector(position=2,sentence=sentence,tag=',',tag_1='NNP',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
